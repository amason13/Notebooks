{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Sentiment Analysis Exercise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbZ_Io_qr48C",
        "colab_type": "text"
      },
      "source": [
        "# Welcome to the PyTorch Sentiment Analysis Exercise\n",
        "\n",
        "This exercise will cover some key concepts in natural language machine learning, including:\n",
        "\n",
        "* The preparation of text datasets\n",
        "* The construction of neural net models for natural language tasks\n",
        "* The use of *recurrent neural network layers,* which are commonly used in problems involving sequences, including natural language tasks.\n",
        "\n",
        "## Notes on Using This Notebook\n",
        "\n",
        "* Code will be provided for boilerplate tasks; in other places, you will need to fill in code to complete the exercise. Cells you need to fill in will be flagged with the **Exercise** heading.\n",
        "* The code cells are, in general, meant to be run in order. If you think a code cell should be working, but it isn't, verify that all previous cells were run - the cell you're having trouble with may depend on a variable or file that is created in a previous cell.\n",
        "* Class names and other text normally meant for consumption by a computer will be rendered in a `monospace font`. This will hopefully reduce confusion between, e.g., the word \"dataset\" referring to the concept of a cohesive body of data, and the class name `Dataset` referring to the related PyTorch class.\n",
        "\n",
        "### Do This Now:\n",
        "\n",
        "The cell below downloads and unzips the dataset we'll be using for this exercise. The dataset isn't huge, but it may take a minute to download, so **please uncomment and execute the following code cell now** to get the process started. (The commented lines are there to prevent the download triggering accidentally, so you may wish to replace them afterward.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_8CZmuLr48E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !curl -0 https://s3-us-west-1.amazonaws.com/pytorch-course-datasets/sentiment-analysis-on-movie-reviews.zip > reviews.zip\n",
        "# !unzip reviews.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDP4he7tsqgV",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This exercise is based on the Kaggle competition, [Sentiment Analysis on Movie Reviews](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/overview). The goal is to accurately classify movie reviews based on how positively they speak of the movie being reviewed.\n",
        "\n",
        "### The Training Dataset\n",
        "\n",
        "Let's have a look at the input data. In `train.tsv`, you should see a file with four fields: A phrase ID, a sentence ID, a phrase, and a sentiment score. (The score runs from 0 to 4, with higher numbers indicating more positive sentiment.) You should see the same content in `test.tsv`, but without the scores.\n",
        "\n",
        "### The Approach\n",
        "\n",
        "There are many approaches to Natural Language Processing (NLP) using deep learning, and they will often include a variety of common neural network constructs, including fully-connected layers, recurrent neural networks (RNNs), convnets, embeddings, and dropouts. For this exercise, we'll be guiding you through constructing a simple model using word embeddings and RNNs, and pointing out directions for further enhancement and exploration.\n",
        "\n",
        "### The Final Step\n",
        "\n",
        "The test dataset is a separate, unlabeled collection of phrases from movie reviews. The final step in today's exercise will be to use your model to classify the unlabeled phrases. You will export your predictions to a file and upload them to the Kaggle site to receive a final accuracy score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7_UZOaAvn-D",
        "colab_type": "text"
      },
      "source": [
        "## Setting Up Your Training Dataset\n",
        "\n",
        "We'll have to build a dataset that can take in our TSV file and transform it to input tensors and labels that PyTorch can consume. For this first pass, we'll set aside the first two columns, and focus on the phrase and the label.\n",
        "\n",
        "Let's look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0wsrH-Hr48J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wc -l train.tsv\n",
        "!head -n 10 train.tsv\n",
        "!wc -l test.tsv\n",
        "!head -n 10 test.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pudHNhP-r48M",
        "colab_type": "text"
      },
      "source": [
        "Fortunately, the `torchtext` module provides us with a `TabularDataset` class that wraps the consumption of CSV, TSV, and JSON-formatted files.\n",
        "\n",
        "In order to use the `torchtext` dataset facilities, we'll need to specify some `Field` objects that describe the data we expect from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whSNA2vK0PoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzcVR1gXJXof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phrases = data.Field(include_lengths=True, tokenize='spacy')\n",
        "labels = data.LabelField(dtype=torch.int64, sequential=False)\n",
        "\n",
        "fields = [\n",
        "    ('SKIP_phrase_id', None),\n",
        "    ('SKIP_sentence_id', None),\n",
        "    ('phrases', phrases),\n",
        "    ('labels', labels)\n",
        "]\n",
        "\n",
        "\n",
        "train_data = data.TabularDataset(\n",
        "    'train.tsv', # path to file\n",
        "    'TSV', # file format\n",
        "    fields,\n",
        "    skip_header = True # we have a header row\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNNrxnaZ22PK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59937331-1285-451f-8ea6-c867ae9b28cd"
      },
      "source": [
        "# check_iter = iter(train_data)\n",
        "# x = check_iter.__next__()\n",
        "# print('---')\n",
        "# print(x.phrases)\n",
        "# print(x.labels) # str wtf\n",
        "\n",
        "check_iter = iter(train_data)\n",
        "maxlen = 0\n",
        "for x in check_iter:\n",
        "    maxlen = max(maxlen, len(x.phrases))\n",
        "print(maxlen)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKJPS74MDYNi",
        "colab_type": "text"
      },
      "source": [
        "Below, we'll define some constants that we'll use for setting up our datasets and training loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCFs1BXoCsHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset constants\n",
        "VOCAB_SIZE = 15000 # max size of vocabulary\n",
        "VOCAB_VECTORS = \"glove.6B.100d\" # Stanford NLP GloVe (global vectors) for word rep\n",
        "\n",
        "# model constants\n",
        "EMBEDDING_SIZE = 100 # must match dimensions in vocab vectors above\n",
        "HIDDEN_SIZE = 100\n",
        "OUTPUT_SIZE = 5 # 0 to 4\n",
        "\n",
        "# training loop constants\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdjyUpk23VAL",
        "colab_type": "text"
      },
      "source": [
        "An important step in any NLP process is *building the vocabulary.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXIc6Gcv90ce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed()\n",
        "\n",
        "train_data, eval_data = train_data.split()\n",
        "\n",
        "phrases.build_vocab(train_data, max_size=VOCAB_SIZE, vectors=VOCAB_VECTORS)\n",
        "labels.build_vocab(train_data)\n",
        "\n",
        "PAD_INDEX = phrases.vocab.stoi[phrases.pad_token]\n",
        "UNKNOWN_INDEX = phrases.vocab.stoi[phrases.unk_token]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_7NSCBgDHkp",
        "colab_type": "text"
      },
      "source": [
        "CPU -> GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc3_47WNAURf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e956c494-f60a-4e3f-9c39-f62737b9f873"
      },
      "source": [
        "if not torch.cuda.is_available():\n",
        "    device = torch.device('cpu')\n",
        "    print('*** GPU not available - running on CPU. ***')\n",
        "else:\n",
        "    device = torch.device('cuda')\n",
        "    print('GPU ready to go!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN1ZFj-HDIla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter, eval_iter = data.BucketIterator.splits(\n",
        "    (train_data, eval_data), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEH8dFjcDqQ7",
        "colab_type": "text"
      },
      "source": [
        "## The Model\n",
        "\n",
        "For this simple model, we'll be using an LSTM - a Long Short-Term Memory layer. This is a type of recurrent neural network that keeps an internal memory that has information added to and removed from it during training, which helps it deal with patterned sequential data.\n",
        "\n",
        "Explanation follows the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjDQyNzbEHsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# class SentimentAnalyzer(nn.Module):\n",
        "    \n",
        "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, pad_index):\n",
        "#         super(SentimentAnalyzer, self).__init__()\n",
        "        \n",
        "#         self.embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
        "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim, dropout=0.5, num_layers=2, bidirectional=True)\n",
        "#         self.scorer = nn.Linear(hidden_dim, 5)\n",
        "    \n",
        "#     def forward(self, phrases, lengths):\n",
        "#         x = self.embed(phrases)\n",
        "#         x = nn.utils.rnn.pack_padded_sequence(x, lengths, enforce_sorted=False)\n",
        "#         _, (hidden_weights, cell_weights) = self.lstm(x)\n",
        "#         # x, out_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "#         x = hidden_weights[-1, :, :].squeeze(0)\n",
        "#         x = self.scorer(x)\n",
        "#         return F.log_softmax(x)\n",
        "\n",
        "class SentimentAnalyzer(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
        "        super(SentimentAnalyzer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        \n",
        "        # TODO check whether we need batch_first=True\n",
        "        self.rnn = nn.RNN(input_size=embedding_size, hidden_size=hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, phrases, hidden):\n",
        "#         print('PHRASES')\n",
        "#         print(phrases.shape)\n",
        "        if hidden is None:\n",
        "            hidden = torch.zeros(1, BATCH_SIZE, self.hidden_size, dtype=torch.float).to(device)\n",
        "#         print('HIDDEN')\n",
        "#         print(hidden.shape)\n",
        "        x = self.embedding(phrases)\n",
        "#         print('EMBEDDING')\n",
        "#         print(x.shape)\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "#         print('RNN')\n",
        "#         print(x.shape)\n",
        "#         print(hidden.shape)\n",
        "        x = self.fc(hidden)\n",
        "#         print('CLASSIFIER')\n",
        "#         print(x.shape)\n",
        "        return x.squeeze(0), hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQIlk1092ZrZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htQT8fCZEoRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "47b6f37f-35e8-4552-9759-f31706418cef"
      },
      "source": [
        "# sa = SentimentAnalyzer(len(phrases.vocab), EMBEDDING_DIM, HIDDEN_DIM, PAD_INDEX)\n",
        "sa = SentimentAnalyzer(len(phrases.vocab), EMBEDDING_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
        "def count_model_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('The model has {} trainable parameters'.format(count_model_params(sa)))\n",
        "print(sa)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1520905 trainable parameters\n",
            "SentimentAnalyzer(\n",
            "  (embedding): Embedding(15002, 100)\n",
            "  (rnn): RNN(100, 100)\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVS6kLUl8sl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10a685ed-fd72-4701-86f5-316d7f6a98f8"
      },
      "source": [
        "pretrained_embeddings = phrases.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmPkDnTK8-Bl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "b55f7d28-b983-449f-ad17-51ee15f795b3"
      },
      "source": [
        "sa.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "# sa.embedding.weight.requires_grad = False\n",
        "# print(sa.embedding.weight.data.shape)\n",
        "# print(pretrained_embeddings.shape)\n",
        "# print(len(phrases.vocab))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.0869,  0.1346,  0.0688,  ..., -0.8253, -0.1474,  0.2279],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0527, -0.0618,  0.0736,  ..., -0.1710,  0.1995,  0.3998]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lexrsIyJAEDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "bfe97ae4-4a1a-4cb4-df9e-57f496b034bb"
      },
      "source": [
        "sa.embedding.weight.data[UNKNOWN_INDEX] = torch.zeros(EMBEDDING_SIZE)\n",
        "sa.embedding.weight.data[PAD_INDEX] = torch.zeros(EMBEDDING_SIZE)\n",
        "\n",
        "print(sa.embedding.weight.data)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.0869,  0.1346,  0.0688,  ..., -0.8253, -0.1474,  0.2279],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0527, -0.0618,  0.0736,  ..., -0.1710,  0.1995,  0.3998]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hgR1tVICSRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def tlog(msg):\n",
        "    print('{}   {}'.format(time.asctime(), msg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q4LPRq4D3Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_correct(guesses, labels):\n",
        "    # g, l = unscale_sentiment_score(guesses), unscale_sentiment_score(labels)\n",
        "    return (guesses == labels).float().sum()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8zFNg_RB3yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, loss_fn, optimizer): # one epoch\n",
        "    curr_loss = 0.\n",
        "    curr_correct = 0.\n",
        "    hidden = None\n",
        "    # model.train() # makes sure that training-only fns, like dropout, are active\n",
        "    \n",
        "    for batch in iterator:\n",
        "        # get the data\n",
        "        phrases, lengths = batch.phrases\n",
        "        \n",
        "        # predict and learn\n",
        "        optimizer.zero_grad()\n",
        "        guesses, hidden = model(phrases, hidden)\n",
        "\n",
        "#         print('***')\n",
        "#         print(guesses.shape)\n",
        "        # guesses = guesses.squeeze(0)\n",
        "#         print('GUESSES')\n",
        "#         print(guesses.shape)\n",
        "#         print('LABELS')\n",
        "#         print(batch.labels.shape)\n",
        "        loss = loss_fn(guesses, batch.labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # measure\n",
        "#         curr_loss += loss.item()\n",
        "#         curr_correct += count_correct(torch.argmax(guesses, 1), batch.labels)\n",
        "        \n",
        "    return curr_loss / len(iterator), curr_correct / (len(iterator) * BATCH_SIZE)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16EFDSvXCDfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, loss_fn):\n",
        "    curr_loss = 0.\n",
        "    curr_correct = 0.\n",
        "    hidden = None\n",
        "    model.eval() # makes sure that training-only fns, like dropout, are inactive\n",
        "    \n",
        "    with torch.no_grad(): # not training\n",
        "        for batch in iterator:\n",
        "            # get the data\n",
        "            phrases, lengths = batch.phrases\n",
        "            \n",
        "            # predict\n",
        "            guesses, hidden = model(phrases, hidden) # .squeeze(1)\n",
        "            loss = loss_fn(guesses, batch.labels)\n",
        "            \n",
        "            # measure\n",
        "            curr_loss += loss.item()\n",
        "            curr_correct += count_correct(guesses, batch.labels)\n",
        "\n",
        "    \n",
        "    return curr_loss / len(iterator), curr_correct / (len(iterator) * BATCH_SIZE)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcErwgP5CKXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learn(model):\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    # loss_fn = loss_fn.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    \n",
        "    for epoch in range(EPOCHS):\n",
        "        tlog('EPOCH {}'.format(epoch))\n",
        "        \n",
        "        train_loss, train_acc = train(model, train_iter, loss_fn, optimizer)\n",
        "        tlog('  Training loss {}'.format(train_loss))\n",
        "        tlog('  Training accuracy {}'.format(train_acc))\n",
        "        \n",
        "        eval_loss, eval_acc = evaluate(model, eval_iter, loss_fn)\n",
        "        tlog('  Validation loss {}'.format(eval_loss))\n",
        "        tlog('  Validation accuracy {}'.format(eval_acc))\n",
        "    \n",
        "    tlog('DONE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v96h30UhE_SK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "3445f80d-3988-46be-df35-983db76a1686"
      },
      "source": [
        "# print(type(sa))\n",
        "\n",
        "learn(sa)\n",
        "# sa.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "# print(type(sa.embedding.weight.data))\n",
        "# print(type(sa.embedding.weight))\n",
        "# print(type(sa.embedding))\n",
        "# sa.embedding.weight.requires_grad = False\n",
        "# print(sa.embedding.weight.requires_grad)\n",
        "# print(pretrained_embeddings.shape)\n",
        "# print(len(phrases.vocab))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May 23 17:56:17 2019   EPOCH 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-8e11d7f75526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# sa.embedding.weight.data.copy_(pretrained_embeddings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(type(sa.embedding.weight.data))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(type(sa.embedding.weight))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-94de962d2aa6>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EPOCH {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Training loss {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Training accuracy {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-71b8195ea745>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         print(batch.labels.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXcaR2yU0JjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}