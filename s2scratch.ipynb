{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "from s2cnn import SO3Convolution\n",
    "from s2cnn import S2Convolution\n",
    "from s2cnn import so3_integrate\n",
    "from s2cnn import so3_near_identity_grid\n",
    "from s2cnn import s2_near_identity_grid\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input0():\n",
    "    return torch.zeros(1,60,60)\n",
    "\n",
    "def inputrand():\n",
    "    return torch.rand(1,60,60)\n",
    "\n",
    "def visualize_tensor_layer(t): # expecting 2D tensor of any size\n",
    "    assert len(t.shape) == 2\n",
    "    for i in range(t.shape[0]):\n",
    "        for j in range(t.shape[1]):\n",
    "            print('{}'.format('1' if t[i][j].item() > 0. else '0'), end='')\n",
    "        print('')\n",
    "\n",
    "def add_light_fuzz(t, fuzz_factor=0.02): # expecting N * 60 * 60, add 2% fuzz\n",
    "    assert fuzz_factor >= 0.\n",
    "    assert fuzz_factor < 1.\n",
    "    out = t.clone()\n",
    "    for i in range(60):\n",
    "        for j in range(60):\n",
    "            if random.random() < fuzz_factor: # 5%ish\n",
    "                out[:,i,j] = 1.\n",
    "    return out\n",
    "        \n",
    "# could pass in all 0s, or add this feature to existing tensor\n",
    "# applies to all layers\n",
    "def make_training_feature1(t): # expecting N * 60 * 60\n",
    "    for i in range(5, 35):\n",
    "        for j in range(5, 35):\n",
    "            x = i - 20\n",
    "            y = j - 20\n",
    "            r2 = x * x + y * y \n",
    "            if r2 > 64 and r2 < 144:\n",
    "                t[:,i,j] = 1.\n",
    "    return t\n",
    "\n",
    "def make_training_feature2(t): # expecting N * 60 * 60\n",
    "    for i in range(30, 60):\n",
    "        for j in range(30, 60):\n",
    "            x = i - 30\n",
    "            y = 60 - j # 0,0 @ ctr btm\n",
    "            if abs(x - y) <= 2:\n",
    "                t[:,i,j] = 1.\n",
    "    return t\n",
    "\n",
    "def make_training_feature3(t): # expecting N * 60 * 60\n",
    "    for i in range(30, 60):\n",
    "        for j in range(0, 30):\n",
    "            if abs(45 - i) <= 2 or abs(15 - j) <= 2:\n",
    "                t[:,i,j] = 1.\n",
    "    return t\n",
    "\n",
    "def make_training_feature4(t):\n",
    "    for i in range(0, 30):\n",
    "        for j in range(30, 60):\n",
    "            x = i\n",
    "            y = 0 - j\n",
    "            if abs(x - y) <= 2 or ((30 - x) - y) <= 2:\n",
    "                t[:,i,j] = 1.\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect_vert(t): # expects 2d tensor\n",
    "    out = t.clone()\n",
    "    assert len(out.shape) == 2\n",
    "    \n",
    "    w = out.shape[0]\n",
    "    h = out.shape[1]\n",
    "    buffer = torch.zeros(h)\n",
    "    for i in range(w // 2):\n",
    "        buffer = out[i, :].clone() # i think i have to clone else broadcasting turns weird?\n",
    "        out[i, :] = out[w - i - 1, :].clone()\n",
    "        out[w - i - 1, :] = buffer\n",
    "    return out\n",
    "\n",
    "def reflect_horiz(t):\n",
    "    return reflect_vert(t.transpose(0,1)).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis each of N kernels separately\n",
    "# each out kernel is a 20^3 tensor in default config\n",
    "# changed to 5 * 10^3 for this run\n",
    "def visualize_s2conv_out(t):\n",
    "    assert len(t.shape) == 4\n",
    "    for kernel in range(t.shape[0]):\n",
    "        print('KERNEL {}'.format(kernel))\n",
    "        outblock = []\n",
    "        for i in range(t.shape[1]): # row * column * depth = grid * depth = block\n",
    "            outgrid = []\n",
    "            for j in range(t.shape[2]): # row * column = grid\n",
    "                outrow = ''\n",
    "                for k in range(t.shape[3]): # row\n",
    "                    outrow += '1' if t[kernel,i,j,k] > 0. else '0'\n",
    "                outgrid.append(outrow)\n",
    "            outblock.append(outgrid)\n",
    "            \n",
    "        visblock = []\n",
    "        for i in range(len(outblock[0])):\n",
    "            visblock.append([])\n",
    "        for i in range(len(outblock)): # pull each grid from block\n",
    "            grid = outblock[i]\n",
    "            for j in range(len(grid)): # pull each row from grid\n",
    "                visblock[j].append(grid[j])\n",
    "        for i in range(len(visblock)):\n",
    "            print(' '.join(visblock[i]))\n",
    "                    \n",
    "def show_conv_layer_for(t, model): # expects 1 * 60 * 60 tensor\n",
    "    torch.unsqueeze(t, 0) # batch\n",
    "    _, _, t_conv = model(t)\n",
    "    visualize_s2conv_out(torch.squeeze(t_conv, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, n_inst=1000, real_only=False, fuzz_factor=None): # make 1000 instances of my training instances plus some bllshit\n",
    "        tf1 = make_training_feature1(input0()) # depends on global fns oops\n",
    "        tf2 = make_training_feature2(input0())\n",
    "        tf3 = make_training_feature3(input0())\n",
    "        tf4 = make_training_feature4(input0())\n",
    "        REAL_FEATURES = 4\n",
    "        MAX_FEATURES = 5\n",
    "        self.instances = []\n",
    "        for _ in range(n_inst):\n",
    "            r = random.randrange(REAL_FEATURES if real_only else MAX_FEATURES)\n",
    "            new_instance = None\n",
    "            if r == 0:\n",
    "                new_instance = tf1 # circle in upper left\n",
    "            elif r == 1:\n",
    "                new_instance = tf2 # SW-NE diag line in lower right\n",
    "            elif r == 2:\n",
    "                new_instance = tf3 # cross upper right\n",
    "            elif r == 3:\n",
    "                new_instance = tf4 # diag cross lower right\n",
    "            else:\n",
    "                new_instance = inputrand() # bullshit\n",
    "            \n",
    "            assert not (new_instance is None)\n",
    "            if (not (fuzz_factor is None)) and r < REAL_FEATURES:\n",
    "                new_instance = add_light_fuzz(new_instance, fuzz_factor=fuzz_factor)\n",
    "            self.instances.append((new_instance, r))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.instances[idx] # tensor, class idx\n",
    "\n",
    "training_dataset = DummyDataset()\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=4, shuffle=True)\n",
    "testing_dataset = DummyDataset(n_inst = 100, real_only=True, fuzz_factor=0.01)\n",
    "testing_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2TestModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(S2TestModel, self).__init__()\n",
    "        self.conv1 = S2Convolution(nfeature_in=1, nfeature_out=10, b_in=30, b_out=5, grid=s2_near_identity_grid())\n",
    "        self.fc1 = torch.nn.Linear(10, 20) # i am just fucking around with this architecture - will it learn?\n",
    "        self.fc2 = torch.nn.Linear(20, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        conv_out = x\n",
    "        # print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = so3_integrate(x)\n",
    "        int_out = x\n",
    "        # print(x.shape)\n",
    "        # activation?\n",
    "        x = self.fc1(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # print(x.shape)\n",
    "        return x, int_out, conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tlog(s):\n",
    "    print('{}: {}'.format(time.asctime(), s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "FUZZ_FACTOR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = DummyDataset(fuzz_factor=FUZZ_FACTOR)\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testing_dataset = DummyDataset(n_inst=100, real_only=True, fuzz_factor=FUZZ_FACTOR)\n",
    "testing_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model = S2TestModel()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    tlog('EPOCH {} of {}'.format(epoch + 1, N_EPOCHS))\n",
    "    \n",
    "    # train\n",
    "    running_loss = 0.\n",
    "    for i, (images, labels) in enumerate(training_loader):\n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        guesses, _, _ = model(images) # discard intermediate outputs\n",
    "        loss = loss_fn(guesses, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 50 == 0:\n",
    "            tlog('iter {}/{}  loss {}  running loss {}'.format(i + 1, len(training_dataset) // BATCH_SIZE, loss.item(), running_loss))\n",
    "    \n",
    "    # validate\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(testing_loader):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            guesses, _, _ = model(images)\n",
    "            _, predictions = torch.max(guesses, 1)\n",
    "            total += labels.size(0) # add batch size to total\n",
    "            correct += (predictions == labels).long().sum().item()\n",
    "    tlog('Test accuracy for epoch {}: {}'.format(epoch, float(correct) / float(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = make_training_feature1(input0()) # depends on global fns oops\n",
    "tf2 = make_training_feature2(input0())\n",
    "tf3 = make_training_feature3(input0())\n",
    "tf4 = make_training_feature4(input0())\n",
    "tfs = [tf1, tf2, tf3, tf4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tf_raw in enumerate(tfs):\n",
    "    tf = torch.squeeze(tf_raw)\n",
    "    tfv = reflect_vert(tf)\n",
    "    tfh = reflect_horiz(tf)\n",
    "    tfvh = reflect_horiz(tfv)\n",
    "    for t_in in [tf, tfv, tfh, tfvh]:\n",
    "        t_in = torch.squeeze(add_light_fuzz(torch.unsqueeze(t_in, 0), fuzz_factor=FUZZ_FACTOR))\n",
    "        guess, _, _ = model(torch.unsqueeze(torch.unsqueeze(t_in, 0), 0))\n",
    "        _, pred = torch.max(guess, 1)\n",
    "        print('got {} for {}'.format(pred.item(), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_out, t_int, t_conv = model(torch.unsqueeze(input0(), 0))\n",
    "print('output shape {}'.format(t_out.shape))\n",
    "print('post-integration shape {}'.format(t_int.shape))\n",
    "print('post-conv shape {}'.format(t_conv.shape))\n",
    "print(torch.squeeze(t_out, 0))\n",
    "print(torch.squeeze(t_int, 0))\n",
    "visualize_s2conv_out(torch.squeeze(t_conv, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_conv_layer_for(tf1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
