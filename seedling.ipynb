{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seedling.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "4yPDz5iJX0BZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Seedling Classification\n",
        "\n",
        "Today, we'll be tackling the Kaggle **Plant Seedlings Classification** problem.\n",
        "\n",
        "The training dataset is a corpus of 4750 images of newly sprouted plants. Each image is labeled as belonging to one of twelve plant species, six of which are crop plants, and six of which are weeds. The goal is to train against the dataset, and correctly classify a set of 794 unlabeled test images.\n",
        "\n",
        "For this exercise, you will be responsible for:\n",
        "\n",
        "* Grooming your data for use by your model\n",
        "* Selecting or designing a model\n",
        "* Training the model against the training dataset\n",
        "* Testing the model against the test dataset\n",
        "* Checking your results on the Kaggle site\n",
        "\n",
        "Some code (e.g., simple code to wrap the images in a dataset) is provided below, so that you can focus on the problem rather than writing boilerplate.\n"
      ]
    },
    {
      "metadata": {
        "id": "SG-K5sWZZk18",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run the code below to download the Kaggle dataset directly to your Colab instance."
      ]
    },
    {
      "metadata": {
        "id": "vZWtHgQfLmPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This cell works great in Google Colab.\n",
        "# If you run it in other environments, your mileage may vary.\n",
        "\n",
        "!wget http://bradheintz.com/kaggle/plant-seedlings-classification.zip\n",
        "!unzip plant-seedlings-classification.zip\n",
        "!mkdir data\n",
        "!unzip train.zip\n",
        "!mv train data\n",
        "!unzip test.zip\n",
        "!mv test data\n",
        "!mkdir models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sT-z10ufXyHO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below are some of the imports we'll need. Note the import of `transforms` from `torchvision` - we'll need this to regularize the images."
      ]
    },
    {
      "metadata": {
        "id": "tZE3QbpfYRQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from imageio import imread\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "import time, argparse, os\n",
        "from os import listdir\n",
        "from os.path import isfile, isdir, join"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4U3kRiBYfkc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The Dataset\n",
        "\n",
        "The `torchvision` package provides the `ImageFolder` dataset object. This object takes a root folder, and expects to find images in subfolders, where each subfolder is the correct label for the image; it exposes this to your code via the `torch.utils.data.Dataset` interface. (Conveniently, you set up just such a root folder in `data/train` when you ran the first cell of this notebook.)\n",
        "\n",
        "The test dataset is constructed a little differently. Here, we *don't* have labels for the instances, but we *do* need the filename of each instance for reporting. (See the test loop later in this notebook for details.) For this reason, I wrote a lightweight `Dataset` subclass that provides the filename with each instance returned by `__getitem__`."
      ]
    },
    {
      "metadata": {
        "id": "fb_1zeZJZyYj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _get_transforms():\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize(100),\n",
        "        transforms.RandomCrop(100),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "def get_training_loader(args, kwargs):\n",
        "    dataset = torchvision.datasets.ImageFolder('data/train', transform=_get_transforms())\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=4, num_workers=2, shuffle=True, **kwargs)\n",
        "  \n",
        "\n",
        "class SeedlingTestDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, path_to_test_data='data/test', transform=None):\n",
        "        self.transform = transform\n",
        "        self.data, self.datasize = self.build_dataset_from_path(path_to_test_data)\n",
        "        self.filenames = sorted(self.data.keys())\n",
        "\n",
        "    def build_dataset_from_path(self, test_data_path):\n",
        "        data = {}\n",
        "        for item in listdir(test_data_path):\n",
        "            file_path = join(test_data_path, item)\n",
        "            if isfile(file_path) and 'png' in file_path:\n",
        "                data[item] = file_path\n",
        "        return data, len(data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.datasize\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        key = self.filenames[index]\n",
        "        full_path = self.data[key]\n",
        "\n",
        "        f = open(full_path, 'rb')\n",
        "        img = Image.open(BytesIO(f.read()))\n",
        "        f.close()\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, key\n",
        "\n",
        "def get_test_loader(args, kwargs):\n",
        "    dataset = SeedlingTestDataset(path_to_test_data='data/test', transform=_get_transforms())\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=1, num_workers=1, shuffle=False, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYMCi4QocbqA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The Model\n",
        "\n",
        "Here's my hand-rolled model. (Later, I'll show an example using transfer learning from a pre-trained model.) It's based very loosely on LeNet 5, and it produces accuracy as high as 82% on the seedling problem. It has about 2.3M parameters, and trains in about 40 minutes on my laptop CPU, or 20 minutes in a Colab instance, using 20 training epochs over the whole training corpus."
      ]
    },
    {
      "metadata": {
        "id": "PP_2pJNMW3Zv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SeedlingModel(nn.Module):\n",
        "\n",
        "    def __init__(self): # model on LeNet-5\n",
        "        super(SeedlingModel, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 30, 7)\n",
        "        self.conv2 = nn.Conv2d(30, 50, 3)\n",
        "        self.fc1 = nn.Linear(50 * 15 * 15, 200)\n",
        "        self.fc2 = nn.Linear(200, 12)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 3, 3)\n",
        "        x = x.view(-1, 50 * 15 * 15)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# to check the number of parameters on your model, try:\n",
        "# print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "# 2270602"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L1RPFsS2cBi1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Also, a utility function for saving the model:"
      ]
    },
    {
      "metadata": {
        "id": "_okhwxJUcARb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _save_model(model, model_dir):\n",
        "    # logger.info(\"Saving the model.\")\n",
        "    print('Saving model')\n",
        "    # savefile = \"seedling-%d.pt\"%(int(time.time()))\n",
        "    savefile = 'seedling-model.pt'\n",
        "    path = os.path.join(model_dir, savefile)\n",
        "    # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
        "    torch.save(model.cpu().state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "unMNhV_Wd2jw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ]
    },
    {
      "metadata": {
        "id": "9uE7PVkabToy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some of the code in this notebook was originally written to work with the `argparse` Python module. Rather than gut the code, here I've made an object to take the place of the parsed arguments, and provide a central point for controlling test inputs and hyperparameters."
      ]
    },
    {
      "metadata": {
        "id": "bBRe-XtybhaV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.epochs = 20\n",
        "        self.use_cuda = True\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.model_dir = 'models'\n",
        "        self.savefile = 'seedling-model.pt'\n",
        "        \n",
        "args = Args()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JGzhnqY-eN2G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The training loop is pretty straightforward. At the end, it saves the model for later use.\n",
        "\n",
        "Also, note the liberal use of user-readable output with timestamps and vital stats (e.g, accumulated loss). When you're not sure how long an operation like a training run will take, this kind of progress reporting can tell you early whether you want to kill a job or let it run."
      ]
    },
    {
      "metadata": {
        "id": "EOKr8jN4d1Zy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _train(model, args):\n",
        "    print('Training the model...')\n",
        "    # skipping distributed stuff at this time\n",
        "    use_cuda = torch.cuda.is_available() and args.use_cuda\n",
        "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
        "    kwargs = {'pin_memory': True} if use_cuda else {}\n",
        "    print('Device: {}'.format(device.type))\n",
        "\n",
        "    train_loader = get_training_loader(args, kwargs)\n",
        "\n",
        "    model = model.to(device)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
        "\n",
        "    print('Training begins: {}'.format(time.asctime()))\n",
        "    \n",
        "    for epoch in range(0, args.epochs):\n",
        "        print('Epoch {} of {}   {}'.format(epoch + 1, args.epochs, time.asctime()))\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels) # TODO should maybe be cross entropy?\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if (i + 1) % 300 == 0:\n",
        "                print('{}, {} loss: {:.6f}   {}'.format(epoch + 1, i + 1, running_loss / 200, time.asctime()))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Training complete: {}'.format(time.asctime()))\n",
        "\n",
        "    _save_model(model, args.model_dir)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8f9zJJomfY3a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's create an instance of the model and training it! If you haven't, make sure to set your Colab instance to run on GPU."
      ]
    },
    {
      "metadata": {
        "id": "aoKy4I5kc2p_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = SeedlingModel()\n",
        "model = _train(model, args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-LB50OdfiMr3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing the Model\n",
        "\n",
        "Below is the test loop for our model. Note that this is *not* the same as a traditional validation loop - we don't have labels for the test set. This loop takes the prediction for each image in the test set and writes it to a CSV file that we can upload to Kaggle to see how well  we did. (More on that shortly.)\n",
        "\n",
        "(Also: Yes, I could have used the `csv` module here, but this is not a tricky output file to write, and haven't we imported enough modules today?)"
      ]
    },
    {
      "metadata": {
        "id": "BMq9KB7CiNam",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_model(model, device, kwargs):\n",
        "    model.eval()\n",
        "    classes = get_training_loader(args, kwargs).dataset.classes # TODO this is horrible\n",
        "    loader = get_test_loader(args, kwargs)\n",
        "    filenames = loader.dataset.filenames\n",
        "\n",
        "    outfile = open('submission.csv', 'w')\n",
        "    outfile.write('file,species\\n')\n",
        "    print('Gathering predictions...   {}'.format(time.asctime()))\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(loader):\n",
        "            output = model(data)\n",
        "            score, pred = torch.max(output, 1)\n",
        "            outfile.write('{},{}\\n'.format(target[0], classes[pred.item()])) # batches of 1\n",
        "    print('Finished predictions, output written to submission.csv   {}'.format(time.asctime()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "irTJiN3MkGYf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Uncomment and run the following code if you want to work from a saved model. If you've been running the cells of this notebook sequentially, you should be able to call the test loop function without this step."
      ]
    },
    {
      "metadata": {
        "id": "p3tG4ZNxjuax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model = SeedlingModel()\n",
        "# with open(os.path.join(args.model_dir, args.savefile), 'rb') as f:\n",
        "#     model.load_state_dict(torch.load(f))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JO9Pb0OykYz0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we'll test the model and get our output .csv of predictions:"
      ]
    },
    {
      "metadata": {
        "id": "Am9zz2kNkc1s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_model(model, 'cpu', {})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfCMg_N3lE83",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If the test ran successfully, you should now be able to take the file `submission.csv`, go to https://www.kaggle.com/c/plant-seedlings-classification/submit (you will have to create a free account), and submit your file for checking."
      ]
    },
    {
      "metadata": {
        "id": "Q3q1psnYllfO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercises, Part 1\n",
        "\n",
        "**Training loop validation:** The training loop, in its current state, does not provide validation of training, meaning that your model is not protected against overfitting and data bias pitfalls. How would you go about splitting the training dataset for training and validation?\n",
        "\n",
        "**Data grooming:** The model above assumes a 100x100, 3-color image as input, and the transforms fed to the dataset (see the `_get_transforms()` function) enforce this. About 10% of the training instances are *less than* 100px wide/high, meaning they'll get upsampled. Is this good, bad, or indifferent? What happens if you discard those samples? Are there other ways to handle them?\n",
        "\n",
        "**Tweaking the model:** Can you identify changes to the model (either by inspection or empirically) that might enhance performance? Run experiments with some of those changes to test your intuition.\n",
        "\n",
        "**Data grooming, part 2:** The pre-trained models (such as the one we use in the next part) that come with the `torchvision` package are trained against ImageNet, which assumes that all image instances are *at least* 224px square. About 50% of the training instances are smaller than this. If you make appropriate adjustments to the model to accommodate a 224x224 image, and make appropriate changes to the transforms to make the incoming images 224px square, does this improve or degrade accuracy? What about speed? Given that half of the training set will have to be upsampled to do this, is there any benefit from discarding some or all of the smaller images?\n",
        "\n",
        "**Data grooming, part 3:** As explained in the [docs](https://pytorch.org/docs/stable/torchvision/models.html) for `torchvision.models`, input images for the pretrained models should be at least 224px wide and high, and normalized with:\n",
        "\n",
        "```\n",
        "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "```\n",
        "\n",
        "These numbers are based on the average mean and standard deviation values for the color channels of the 1.2 million images of the ImageNet corpus. This transform shifts the distribution of pixel color values to be a normal distribution centered on 0, with values between -1 and 1. This is beneficial because most activation functions have their steepest gradients near 0, and (with some obvious exceptions like ReLU) tend to saturate quickly for absolute values greater than 1.\n",
        "\n",
        "Try taking the mean and standard deviation values for the colorspace of the seedling training images, and normalizing the images using a transform like the one above (but with your values substituted). How does this affect accuracy? Speed?"
      ]
    }
  ]
}