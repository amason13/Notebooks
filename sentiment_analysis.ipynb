{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Q-DoPGl0j7gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import time\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k16HBOovsZ0U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below are some helpers, and a few lines to nudge you to change your Colab runtime to GPU (just in case you hadn't already)."
      ]
    },
    {
      "metadata": {
        "id": "pHWwa-4JlM78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa4bbcad-b9e0-41ab-beb4-e96d06a3870e"
      },
      "cell_type": "code",
      "source": [
        "def tlog(msg):\n",
        "    print('{}  {}'.format(time.asctime(), msg))\n",
        "\n",
        "\n",
        "# If possible, we should be running on GPU\n",
        "if not torch.cuda.is_available():\n",
        "    print('If you are running this notebook in Colab, go to the Runtime menu and select \"Change runtime type\" to switch to GPU.')\n",
        "else:\n",
        "    print('GPU ready to go!')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MSjpzwUQsYyx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "teknD8kimZUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# indices\n",
        "I_PHRASE_ID = 0\n",
        "I_SENTENCE_ID = 1\n",
        "I_PHRASE = 2\n",
        "I_LABEL = 3\n",
        "I_TOKEN_LIST = 4\n",
        "\n",
        "class RottenTomatoesDataset(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        raw_rows = [] # raw input\n",
        "        vocab = set() # build vocabulary for embeddings\n",
        "        \n",
        "        with open('train.tsv') as tsvfile:\n",
        "            tlog('Loading training data...')\n",
        "            reader = csv.reader(tsvfile, delimiter='\\t')\n",
        "            count = 0\n",
        "            exceptions = 0\n",
        "            max_sentence = 0\n",
        "            for row in reader: # assuming sorted by sentenceid, phraseid\n",
        "                if count > 0: # skip header\n",
        "                    phraseID = int(row[I_PHRASE_ID])\n",
        "                    sentenceID = int(row[I_SENTENCE_ID])\n",
        "                    label = int(row[I_LABEL])\n",
        "                    if phraseID > 0 and sentenceID > 0 and label >= 0:\n",
        "                        row[I_PHRASE_ID] = phraseID\n",
        "                        row[I_SENTENCE_ID] = sentenceID\n",
        "                        row[I_LABEL] = label\n",
        "                        raw_rows.append(row)\n",
        "                        max_sentence = max(max_sentence, sentenceID)\n",
        "                    else:\n",
        "                        print('EXCEPTION')\n",
        "                        print(row)\n",
        "                        exceptions += 1\n",
        "                count += 1\n",
        "            \n",
        "            # break into training & validation\n",
        "            tlog('Splitting training and validation sets...')\n",
        "            i = 0\n",
        "            while raw_rows[i][I_SENTENCE_ID] < (max_sentence * 0.8):\n",
        "                i += 1\n",
        "            self.training_rows, self.validation_rows = raw_rows[:i], raw_rows[i:]\n",
        "            \n",
        "            # gather tokens and set up embedding\n",
        "            last_sentence_parsed = 0\n",
        "            for row in raw_rows:\n",
        "                sent_id = row[I_SENTENCE_ID]\n",
        "                if sent_id > last_sentence_parsed:\n",
        "                    tokens = row[I_PHRASE].split(' ')\n",
        "                    for token in tokens:\n",
        "                        vocab.add(token) # make them unique\n",
        "            vocab = list(vocab)\n",
        "\n",
        "            # wrap it up\n",
        "            self.training = True\n",
        "            tlog('Finished loading training data:')\n",
        "            tlog('  {} exceptions in {} rows ({} good records)'.format(exceptions, count, count - exceptions))\n",
        "            tlog('  token count {}'.format(len(vocab)))\n",
        "    \n",
        "    def train(self):\n",
        "        self.training = True\n",
        "    \n",
        "    def validate(self):\n",
        "        self.training = False\n",
        "    \n",
        "    def current_dataset(self):\n",
        "        if self.training:\n",
        "            return self.training_rows\n",
        "        return self.validation_rows\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.current_dataset())\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.current_dataset()[idx]\n",
        "        return (row[I_PHRASE_ID], row[I_SENTENCE_ID], row[I_PHRASE]), row[I_LABEL]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDpAWgpFvBR-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I've set up a single dataset class that (crudely) splits the set between training and validation sets with a roughly 80/20 split - see the cell below for usage."
      ]
    },
    {
      "metadata": {
        "id": "ic-xV3fSrGFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8b928aaf-eb1d-4450-ae81-a54b462bebf4"
      },
      "cell_type": "code",
      "source": [
        "dataset = RottenTomatoesDataset()\n",
        "dataset.train()\n",
        "print(len(dataset))\n",
        "dataset.validate()\n",
        "print(len(dataset))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr 24 00:48:35 2019  Loading training data...\n",
            "Wed Apr 24 00:48:35 2019  Splitting training and validation sets...\n",
            "Wed Apr 24 00:48:35 2019  Finished loading training data:\n",
            "Wed Apr 24 00:48:35 2019    0 exceptions in 156061 rows (156061 good records)\n",
            "Wed Apr 24 00:48:35 2019    token count 18227\n",
            "127101\n",
            "28959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3cTECxfUvSr6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MK8BVxtdvUYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training loop"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}