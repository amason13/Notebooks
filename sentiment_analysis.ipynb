{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Q-DoPGl0j7gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import time\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k16HBOovsZ0U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below are some helpers, and a few lines to nudge you to change your Colab runtime to GPU (just in case you hadn't already)."
      ]
    },
    {
      "metadata": {
        "id": "pHWwa-4JlM78",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tlog(msg):\n",
        "    print('{}   {}'.format(time.asctime(), msg))\n",
        "\n",
        "\n",
        "# If possible, we should be running on GPU\n",
        "if not torch.cuda.is_available():\n",
        "    print('If you are running this notebook in Colab, go to the Runtime menu and select \"Change runtime type\" to switch to GPU.')\n",
        "else:\n",
        "    print('GPU ready to go!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MSjpzwUQsYyx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "teknD8kimZUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# indices\n",
        "I_PHRASE_ID = 0\n",
        "I_SENTENCE_ID = 1\n",
        "I_PHRASE = 2\n",
        "I_LABEL = 3\n",
        "\n",
        "class RottenTomatoesDataset(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        raw_rows = []\n",
        "        with open('train.tsv') as tsvfile:\n",
        "            tlog('Loading training data...')\n",
        "            reader = csv.reader(tsvfile, delimiter='\\t')\n",
        "            count = 0\n",
        "            exceptions = 0\n",
        "            max_sentence = 0\n",
        "            for row in reader: # assuming sorted by sentenceid, phraseid\n",
        "                if count > 0: # skip header\n",
        "                    phraseID = int(row[I_PHRASE_ID])\n",
        "                    sentenceID = int(row[I_SENTENCE_ID])\n",
        "                    label = int(row[I_LABEL])\n",
        "                    if phraseID > 0 and sentenceID > 0 and label > 0:\n",
        "                        row[I_PHRASE_ID] = phraseID\n",
        "                        row[I_SENTENCE_ID] = sentenceID\n",
        "                        row[I_LABEL] = label\n",
        "                        raw_rows.append(row)\n",
        "                        max_sentence = max(max_sentence, sentenceID)\n",
        "                    else:\n",
        "                        exceptions += 1\n",
        "                count += 1\n",
        "            \n",
        "            # break into training & validation\n",
        "            for i in range(len(raw_rows)):\n",
        "                if (max_sentence * 0.8) > raw_rows[i][I_SENTENCE_ID]:\n",
        "                    self.training_rows, self.validation_rows = raw_rows[:i], raw_rows[i:]\n",
        "            self.training = True\n",
        "            tlog('Finished loading training data')\n",
        "    \n",
        "    def training(self):\n",
        "        self.training = True\n",
        "    \n",
        "    def validating(self):\n",
        "        self.training = False\n",
        "    \n",
        "    def current_dataset(self):\n",
        "        if self.training:\n",
        "            return self.training_rows\n",
        "        return self.validation_rows\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.current_dataset())\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.current_dataset()[idx]\n",
        "        return (row[I_PHRASE_ID], row[I_SENTENCE_ID], row[I_PHRASE]), row[I_LABEL]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ic-xV3fSrGFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d0626d3-7879-4a66-dead-3d68bd0ed8db"
      },
      "cell_type": "code",
      "source": [
        "dataset = RottenTomatoesDataset()\n",
        "dataset.training()\n",
        "print(len(dataset))\n",
        "dataset.validating()\n",
        "print(len(dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr 24 00:13:41 2019   Loading training data...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}