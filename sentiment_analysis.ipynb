{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Q-DoPGl0j7gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import time\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k16HBOovsZ0U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below are some helpers, and a few lines to nudge you to change your Colab runtime to GPU (just in case you hadn't already)."
      ]
    },
    {
      "metadata": {
        "id": "pHWwa-4JlM78",
        "colab_type": "code",
        "outputId": "14098d5a-86cf-4714-f5c8-68f5b4ce8353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def tlog(msg):\n",
        "    print('{}  {}'.format(time.asctime(), msg))\n",
        "\n",
        "\n",
        "# If possible, we should be running on GPU\n",
        "if not torch.cuda.is_available():\n",
        "    print('If you are running this notebook in Colab, go to the Runtime menu and select \"Change runtime type\" to switch to GPU.')\n",
        "else:\n",
        "    print('GPU ready to go!')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MSjpzwUQsYyx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "teknD8kimZUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# indices\n",
        "I_PHRASE_ID = 0\n",
        "I_SENTENCE_ID = 1\n",
        "I_PHRASE = 2\n",
        "I_LABEL = 3\n",
        "I_TOKEN_LIST = 4\n",
        "\n",
        "# constants\n",
        "NULL_TOKEN = '<NULLTOKEN>'\n",
        "MAX_SENTENCE_LENGTH = 200\n",
        "\n",
        "\n",
        "class RottenTomatoesDataset(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        self.classes = [0,1,2,3,4] # sentiment scores\n",
        "        \n",
        "        raw_rows = [] # raw input\n",
        "        \n",
        "        with open('train.tsv') as tsvfile:\n",
        "            tlog('Loading training data...')\n",
        "            reader = csv.reader(tsvfile, delimiter='\\t')\n",
        "            count = 0\n",
        "            exceptions = 0\n",
        "            max_sentence = 0\n",
        "            for row in reader: # assuming sorted by sentenceid, phraseid\n",
        "                if count > 0: # skip header\n",
        "                    phraseID = int(row[I_PHRASE_ID])\n",
        "                    sentenceID = int(row[I_SENTENCE_ID])\n",
        "                    label = int(row[I_LABEL])\n",
        "                    if phraseID > 0 and sentenceID > 0 and label >= 0:\n",
        "                        row[I_PHRASE_ID] = phraseID\n",
        "                        row[I_SENTENCE_ID] = sentenceID\n",
        "                        row[I_LABEL] = label\n",
        "                        raw_rows.append(row)\n",
        "                        max_sentence = max(max_sentence, sentenceID)\n",
        "                    else:\n",
        "                        print('EXCEPTION')\n",
        "                        print(row)\n",
        "                        exceptions += 1\n",
        "                count += 1\n",
        "            \n",
        "            \n",
        "            # gather tokens\n",
        "            (self.vocab_map, self.enriched_rows) = self.build_vocab_and_map_phrases(raw_rows)\n",
        "            \n",
        "            # break into training & validation\n",
        "            tlog('Splitting training and validation sets...')\n",
        "            i = 0\n",
        "            while self.enriched_rows[i][I_SENTENCE_ID] < (max_sentence * 0.8):\n",
        "                i += 1\n",
        "            self.training_rows, self.validation_rows = self.enriched_rows[:i], self.enriched_rows[i:]\n",
        "\n",
        "            # wrap it up\n",
        "            self.training = True\n",
        "            tlog('Finished loading training data:')\n",
        "            tlog('  {} exceptions in {} rows ({} good records)'.format(exceptions, count, count - exceptions))\n",
        "            tlog('  token count {}'.format(len(vocab)))\n",
        "\n",
        "    # helpers\n",
        "    def build_vocab_and_map_phrases(self, raw_rows):\n",
        "        tlog('Building vocabulary...')\n",
        "        vocab = set()\n",
        "        last_sentence_parsed = 0\n",
        "        for row in raw_rows:\n",
        "            sent_id = row[I_SENTENCE_ID]\n",
        "            if sent_id > last_sentence_parsed:\n",
        "                tokens = row[I_PHRASE].split(' ')\n",
        "                for token in tokens:\n",
        "                    vocab.add(token) # make them unique\n",
        "        vocab = list(vocab)\n",
        "        vocab.append(NULL_TOKEN)\n",
        "        vocab_map = {vocab[i]: i for i in range(len(vocab))}\n",
        "        \n",
        "        tlog('Mapping phrases to one-hot vectors...')\n",
        "        \n",
        "        enriched_rows = raw_rows\n",
        "        for i, row in enumerate(enriched_rows):\n",
        "            if i % 10000 == 0: tlog('  mapping row {} of {}'.format(i, len(raw_rows)))\n",
        "            token_list = []\n",
        "            tokens = row[I_PHRASE].split(' ')\n",
        "            for token in tokens:\n",
        "                if token in vocab:\n",
        "                    token_list.append(vocab_map[token])\n",
        "                else:\n",
        "                    token_list.append(vocab_map[NULL_TOKEN])\n",
        "            token_list = torch.tensor(token_list, dtype=torch.long)\n",
        "            padded_token_list = torch.zeros(MAX_SENTENCE_LENGTH)\n",
        "            padded_token_list[:len(token_list)] = token_list\n",
        "            row.append(padded_token_list)\n",
        "            \n",
        "        tlog('Finished vocabulary mapping')\n",
        "        return vocab_map, enriched_rows\n",
        "    \n",
        "    \n",
        "    # two states, training and validation\n",
        "    def train(self):\n",
        "        self.training = True\n",
        "    \n",
        "    def validate(self):\n",
        "        self.training = False\n",
        "    \n",
        "    def current_dataset(self):\n",
        "        if self.training:\n",
        "            return self.training_rows\n",
        "        return self.validation_rows\n",
        "\n",
        "    # the obligatory\n",
        "    def __len__(self):\n",
        "        return len(self.current_dataset())\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.current_dataset()[idx]\n",
        "        return row[I_TOKEN_LIST], row[I_LABEL]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDpAWgpFvBR-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I've set up a single dataset class that (crudely) splits the set between training and validation sets with a roughly 80/20 split - see the cell below for usage."
      ]
    },
    {
      "metadata": {
        "id": "ic-xV3fSrGFi",
        "colab_type": "code",
        "outputId": "db88e682-e9ac-474b-b892-2106493aeecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        }
      },
      "cell_type": "code",
      "source": [
        "dataset = RottenTomatoesDataset()\n",
        "dataset.train()\n",
        "print(len(dataset))\n",
        "dataset.validate()\n",
        "print(len(dataset))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr 24 05:27:52 2019  Loading training data...\n",
            "Wed Apr 24 05:27:53 2019  Building vocabulary...\n",
            "Wed Apr 24 05:27:53 2019  Mapping phrases to one-hot vectors...\n",
            "Wed Apr 24 05:27:53 2019    mapping row 0 of 156060\n",
            "Wed Apr 24 05:28:01 2019    mapping row 10000 of 156060\n",
            "Wed Apr 24 05:28:09 2019    mapping row 20000 of 156060\n",
            "Wed Apr 24 05:28:18 2019    mapping row 30000 of 156060\n",
            "Wed Apr 24 05:28:28 2019    mapping row 40000 of 156060\n",
            "Wed Apr 24 05:28:38 2019    mapping row 50000 of 156060\n",
            "Wed Apr 24 05:28:47 2019    mapping row 60000 of 156060\n",
            "Wed Apr 24 05:28:57 2019    mapping row 70000 of 156060\n",
            "Wed Apr 24 05:29:07 2019    mapping row 80000 of 156060\n",
            "Wed Apr 24 05:29:18 2019    mapping row 90000 of 156060\n",
            "Wed Apr 24 05:29:28 2019    mapping row 100000 of 156060\n",
            "Wed Apr 24 05:29:38 2019    mapping row 110000 of 156060\n",
            "Wed Apr 24 05:29:49 2019    mapping row 120000 of 156060\n",
            "Wed Apr 24 05:29:59 2019    mapping row 130000 of 156060\n",
            "Wed Apr 24 05:30:09 2019    mapping row 140000 of 156060\n",
            "Wed Apr 24 05:30:19 2019    mapping row 150000 of 156060\n",
            "Wed Apr 24 05:30:25 2019  Finished vocabulary mapping\n",
            "Wed Apr 24 05:30:25 2019  Splitting training and validation sets...\n",
            "Wed Apr 24 05:30:25 2019  Finished loading training data:\n",
            "Wed Apr 24 05:30:25 2019    0 exceptions in 156061 rows (156061 good records)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-ae271f05acfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRottenTomatoesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-f2c09731441a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mtlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished loading training data:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mtlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  {} exceptions in {} rows ({} good records)'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mtlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  token count {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vixvL-G3ZJIT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The simple RNN-based network below transforms the input as follows:\n",
        "\n",
        "1) Initially, the input tensor has a one-hot vector with the same dimensionality as the dataset's total vocabulary. The Embedding layer converts this to a denser representation as a floating-point vector.\n",
        "\n",
        "2) The RNN layer maintains a hidden state that allows it to capture context from short sequences.\n",
        "\n",
        "3) Finally, the Linear layer classifies the phrase into one of our five sentiment classes (0-4)."
      ]
    },
    {
      "metadata": {
        "id": "poJiPqR_bgnE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c595a353-2636-4bb9-acf7-cd57ba6599f7"
      },
      "cell_type": "code",
      "source": [
        "for _, (sen, label) in enumerate(dataset):\n",
        "    print(sen)\n",
        "    break\n",
        "    "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 6786.,  2956., 11505.,  3376.,   655.,  1990., 16465.,  3547.,  8038.,\n",
            "         3766.,  4429.,   129.,  1046., 17724., 17706.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3cTECxfUvSr6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SentimentSeeker(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_classes):\n",
        "        super(SentimentSeeker, self).__init__()\n",
        "        \n",
        "        self.embed = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = torch.nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.classifier = torch.nn.Linear(hidden_dim, n_classes)\n",
        "        \n",
        "    def forward(self, sen): # input vector of max sentence length containing one-hots\n",
        "        embedded = self.embed(sen) # adds embedded dim\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        return self.classfier(hidden.squeeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VbmSBz5qnywY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = SentimentSeeker(len(dataset.vocab_map), 32, 128, len(dataset.classes))\n",
        "# dataset.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MK8BVxtdvUYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training constants\n",
        "N_EPOCHS = 2\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
        "model = SentimentSeeker(len(dataset.vocab_map), 32, 128, dataset.classes)\n",
        "\n",
        "# training loop\n",
        "for epoch in range(N_EPOCHS):\n",
        "    tlog('Epoch {} of {}'.format(epoch, N_EPOCHS))\n",
        "    \n",
        "    for batch_idx, ((_, _, token_list), label) in enumerate(dataloader):\n",
        "        sentences = \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}